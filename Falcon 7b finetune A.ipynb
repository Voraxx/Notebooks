{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MewpxQTj1DR_5tjlGs_RZpwnH9GJW7vT","timestamp":1690394810537},{"file_id":"1IqL0ay04RwNNcn5R7HzhgBqZ2lPhHloh","timestamp":1690377897013}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkLQo3pmo-Jk","executionInfo":{"status":"ok","timestamp":1690395696741,"user_tz":-120,"elapsed":119476,"user":{"displayName":"Adrian Mo","userId":"05907936301149722276"}},"outputId":"58df69ea-1615-4705-95ce-51f7f8de02c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: Did not find branch or tag 'e03a9cc', assuming revision or ref.\u001b[0m\u001b[33m\n","\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: Did not find branch or tag '42a184f', assuming revision or ref.\u001b[0m\u001b[33m\n","\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: Did not find branch or tag 'c9fbb71', assuming revision or ref.\u001b[0m\u001b[33m\n","\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -Uqqq pip\n","!pip install -qqq bitsandbytes==0.39.0\n","!pip install -qqq torch==2.0.1\n","!pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc\n","!pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f\n","!pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71\n","!pip install -qqq datasets==2.12.0\n","!pip install -qqq loralib==0.1.1\n","!pip install -qqq einops==0.6.1"]},{"cell_type":"code","source":["import json\n","import os\n","from pprint import pprint\n","import bitsandbytes as bnb\n","import torch\n","import torch.nn as nn\n","import transformers\n","from datasets import load_dataset\n","from huggingface_hub import notebook_login\n","from peft import (\n","    LoraConfig,\n","    PeftConfig,\n","    PeftModel,\n","    get_peft_model,\n","    prepare_model_for_kbit_training\n",")\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig\n",")\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"metadata":{"id":"YNvT2Uynpit-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notebook_login()"],"metadata":{"id":"5bdd0Xi0ppev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LOAD FALCON MODEL & TOKENIZER"],"metadata":{"id":"2bh3J5Ndp1lO"}},{"cell_type":"code","source":["#MODEL_NAME = \"tiiuae/falcon-40b-instruct\"\n","MODEL_NAME = \"tiiuae/falcon-7b-instruct\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n","    quantization_config=bnb_config\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"1GUD7mBRp2qH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_trainable_parameters(model):\n","  \"\"\"\n","  Prints the number of trainable parameters in the model.\n","  \"\"\"\n","  trainable_params = 0\n","  all_param = 0\n","  for _, param in model.named_parameters():\n","    all_param += param.numel()\n","    if param.requires_grad:\n","      trainable_params += param.numel()\n","  print(\n","      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n","  )"],"metadata":{"id":"RsxPa1WmmktC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"VsvSHI6lml1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"query_key_value\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"],"metadata":{"id":"6IgfANNJmnGx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test original model"],"metadata":{"id":"NvUWzHR9p8nz"}},{"cell_type":"code","source":["prompt = \"\"\"\n","<human>: midjourney prompt for a girl sit on the mountain\n","<assistant>:\n","\"\"\".strip()"],"metadata":{"id":"VB1lR2Yep-Im"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generation_config = model.generation_config\n","generation_config.max_new_tokens = 200\n","generation_config.temperature = 0.7\n","generation_config.top_p = 0.7\n","generation_config.num_return_sequences = 1\n","generation_config.pad_token_id = tokenizer.eos_token_id\n","generation_config.eos_token_id = tokenizer.eos_token_id"],"metadata":{"id":"Yu4xood_p_eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","device = \"cuda:0\"\n","\n","encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","with torch.inference_mode():\n","  outputs = model.generate(\n","      input_ids = encoding.input_ids,\n","      attention_mask = encoding.attention_mask,\n","      generation_config = generation_config\n","  )\n","\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"],"metadata":{"id":"3l8_DfXuqBLu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prep dataset"],"metadata":{"id":"lnnzcwuKqGn0"}},{"cell_type":"code","source":["data = load_dataset(\"csv\", data_files=\"midjourney_prompt_dataset.csv\")"],"metadata":{"id":"XVpOQJnSqJYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"JPBLGZDcqX6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[\"train\"][0]"],"metadata":{"id":"GbjbejfPqbYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompt(data_point):\n","  return f\"\"\"\n","<human>: {data_point[\"User\"]}\n","<assistant>: {data_point[\"Prompt\"]}\n","\"\"\".strip()\n","\n","def generate_and_tokenize_prompt(data_point):\n","  full_prompt = generate_prompt(data_point)\n","  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n","  return tokenized_full_prompt"],"metadata":{"id":"UcNlEuwnqh4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)"],"metadata":{"id":"i4jK1V20qiac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"v4w31zK0qk7A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finetune the model"],"metadata":{"id":"kf_Vy70HsKGQ"}},{"cell_type":"code","source":["training_args = transformers.TrainingArguments(\n","      per_device_train_batch_size=1,\n","      gradient_accumulation_steps=4,\n","      num_train_epochs=1,\n","      learning_rate=2e-4,\n","      fp16=True,\n","      save_total_limit=3,\n","      logging_steps=1,\n","      output_dir=\"experiments\",\n","      optim=\"paged_adamw_8bit\",\n","      lr_scheduler_type=\"cosine\",\n","      warmup_ratio=0.05,\n",")\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=data,\n","    args=training_args,\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",")\n","model.config.use_cache = False\n","trainer.train()"],"metadata":{"id":"UTjSAkYUsQqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save trained model"],"metadata":{"id":"S0JaaueJs3Tt"}},{"cell_type":"code","source":["model.save_pretrained(\"trained-model\")"],"metadata":{"id":"bFCETjids62_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PEFT_MODEL = \"jzdesign/midjourney-falcon-7b\"\n","\n","model.push_to_hub(\n","    PEFT_MODEL, use_auth_token=True\n",")"],"metadata":{"id":"sl_IzzKdtFtG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = PeftConfig.from_pretrained(PEFT_MODEL)\n","model = AutoModelForCausalLM.from_pretrained(\n","    config.base_model_name_or_path,\n","    return_dict=True,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = PeftModel.from_pretrained(model, PEFT_MODEL)"],"metadata":{"id":"1mUR2fpbtI7-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run the finetuned model"],"metadata":{"id":"jIs2DDuetQzF"}},{"cell_type":"code","source":["generation_config = model.generation_config\n","generation_config.max_new_tokens = 200\n","generation_config.temperature = 0.7\n","generation_config.top_p = 0.7\n","generation_config.num_return_sequences = 1\n","generation_config.pad_token_id = tokenizer.eos_token_id\n","generation_config.eos_token_id = tokenizer.eos_token_id"],"metadata":{"id":"ArdOBIwgtRQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","device = \"cuda:0\"\n","\n","prompt = \"\"\"\n","<human>: midjourney prompt for a boy running in the snow\n","<assistant>:\n","\"\"\".strip()\n","\n","encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","with torch.inference_mode():\n","  outputs = model.generate(\n","      input_ids = encoding.input_ids,\n","      attention_mask = encoding.attention_mask,\n","      generation_config = generation_config\n","  )\n","\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"],"metadata":{"id":"WvzZUmTttSgR"},"execution_count":null,"outputs":[]}]}