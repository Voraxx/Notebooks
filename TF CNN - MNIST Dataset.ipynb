{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6dKxVJnSCcKtkLO5HceN3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Classifying Images of Clothing using TensorFlow\n","\n","tf.keras\n","\n","\n"],"metadata":{"id":"qAnVxVLq_1Au"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN5K6U_f_B4e"},"outputs":[],"source":["!pip install -U tensorflow_datasets"]},{"cell_type":"code","source":["# Install and import dependencies\n","import tensorflow as tf\n","\n","# Import TensorFlow Datasets\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","# Helper libraries\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import logging\n","logger = tf.get_logger()\n","logger.setLevel(logging.ERROR)\n","\n","# Use a subset of the Fashio MNIST dataset with 60k images for training and 10k images for testing\n","dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n","train_dataset, test_dataset = dataset['train'], dataset['test']\n","\n","# store class names here to use later when plotting the images:\n","class_names = metadata.features['label'].names\n","print(\"Class names: {}\".format(class_names))\n","\n","# Explore the data\n","num_train_examples = metadata.splits['train'].num_examples\n","num_test_examples = metadata.splits['test'].num_examples\n","print(\"Number of training examples: {}\".format(num_train_examples))\n","print(\"Number of test examples:     {}\".format(num_test_examples))\n","\n","\n","# Preprocess the data\n","# The value of each pixel in the image data is an integer in the range [0,255].\n","# For the model to work properly, these values need to be normalized to the range [0,1].\n","# Apply normalize function to each image in the test and train datasets.\n","def normalize(images, labels):\n","  images = tf.cast(images, tf.float32)\n","  images /= 255\n","  return images, labels\n","\n","# The map function applies the normalize function to each element in the train\n","# and test datasets\n","train_dataset =  train_dataset.map(normalize)\n","test_dataset  =  test_dataset.map(normalize)\n","\n","# The first time you use the dataset, the images will be loaded from disk\n","# Caching will keep them in memory, making training faster\n","train_dataset =  train_dataset.cache()\n","test_dataset  =  test_dataset.cache()\n","\n","\n","# Explore the preprocessed data:\n","# Take a single image, and remove the color dimension by reshaping\n","for image, label in test_dataset.take(1):\n","  break\n","image = image.numpy().reshape((28,28))\n","# Plot the image - voila a piece of fashion clothing\n","plt.figure()\n","plt.imshow(image, cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()\n","\n","# Display the first 25 images from the training set and display the class name below each image.\n","# Verify that the data is in the correct format and we're ready to build and train the network.\n","plt.figure(figsize=(10,10))\n","for i, (image, label) in enumerate(train_dataset.take(25)):\n","    image = image.numpy().reshape((28,28))\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(image, cmap=plt.cm.binary)\n","    plt.xlabel(class_names[label])\n","plt.show()\n","\n","\n","# Setup the layers\n","# The basic building block of a neural network is the layer.\n","# A layer extracts a representation from the data fed into it.\n","# Hopefully, a series of connected layers results in a representation that is meaningful for the problem at hand.\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape = (28, 28, 1)),\n","    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n","    tf.keras.layers.Dense( 10, activation = tf.nn.softmax)\n","])\n","\n","\n","# Compile the model:\n","model.compile(optimizer = 'adam',\n","              loss      = tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics   = ['accuracy'])\n","\n","\n"],"metadata":{"id":"fPXFHFVf_OMY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## <b>This network has three layers:</b>\n","<p><b>input: </b><code>tf.keras.layers.Flatten</code></p>\n","This layer transforms the images from a 2d-array of 28 Ã— 28 pixels, to a 1d-array of 784 pixels (28*28).\n","Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn, as it only reformats the data.\n","\n","<p><b>hidden: </b><code>tf.keras.layers.Dense</code></p>\n","A densely connected layer of 128 neurons. Each neuron (or node) takes input from all 784 nodes in the previous layer, weighting that input according to hidden parameters which will be learned during training, and outputs a single value to the next layer.\n","\n","<p><b>output: </b><code>tf.keras.layers.Dense</code></p>\n","A 128-neuron, followed by 10-node softmax layer. Each node represents a class of clothing. As in the previous layer, the final layer takes input from the 128 nodes in the layer before it, and outputs a value in the range [0, 1], representing the probability that the image belongs to that class. The sum of all 10 node values is 1.\n","\n","<p><b>Note:</b></p>\n","Using softmax activation and SparseCategoricalCrossentropy() has issues and which are patched by the tf.keras model.\n","A safer approach, in general, is to use a linear output (no activation function) with SparseCategoricalCrossentropy(from_logits=True).\n","\n","<p><b>Training the model</b></p>\n","First, we define the iteration behavior for the train dataset:\n","\n","Repeat forever by specifying dataset.repeat() (the epochs parameter described below limits how long we perform training).\n","The dataset.shuffle(60000) randomizes the order so our model cannot learn anything from the order of the examples.\n","And dataset.batch(32) tells model.fit to use batches of 32 images and labels when updating the model variables.\n","\n","Training is performed by calling the model.fit method:\n","\n","Feed the training data to the model using train_dataset.\n","The model learns to associate images and labels.\n","The epochs=5 parameter limits training to 5 full iterations of the training dataset, so a total of 5 * 60000 = 300000 examples.\n"],"metadata":{"id":"NhIRiHYcCTwF"}}]}